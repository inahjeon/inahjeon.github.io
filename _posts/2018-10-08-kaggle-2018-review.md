---
layout: post
title:  "캐글뽀개기 2018 세션 노트"
date:   2018-10-08 00:55:00
tags: [conference]
comments: true
---

## 기업 현장에서의 데이터 과학: 조동환님
1) SKT DT 조직의 데이터 인프라
raw data(정형데이터/비정형데이터/외부데이터 등) to data lake

- data lake : 데이터를 가공하기 전에 모아두는 곳.

data lake가 데이터 쓰레기장이 되지 않으려면 데이터의 형태, 데이터에 대한 설명 등 잘 관리되어 있어야함.

- data ware house: 분석하기 위해 가공된 데이터 저장소.

data lake to data services
- data lake -> feature store -> ml engine -> data analysis
- data lake -> fast data store (일부 기간 데이터) -> data service

2) Data 기반 조직으로 변화 시키기

조직이 data 기반으로 움직이도록 하기 위해서 변화를 어떻게 이끌어 낼 것 인지가 매우 중요!

(2)번 내용이 더 중요했는데, 필기를 많이 못했음..ㅜ)

## Mastering Machine Learning with Competitions: 이정윤님

왜 kaggle 해야하는지

Competition 팁들
- validation set을 잘 정의하는 게 중요!
- 효율화를 위해 pipeline이 있어야함 (피쳐엔지니어링 / 학습 / submission 등 단계 관리)

## Show me the Kaggle medal: 이유한님

캐글 진행 과정:
1. feature engineering
- ratio feature : A per B
ex) 연금 / 전체수입
- product feature: A * B
- Addition feature: A + B
- Subtraction feature: A + B
- Aggregation Feature: category와 numerial feature의 조합
- category feature: one-hot / label encoding / lightgbm (가장 성능이 좋다고함)
(lightgbm-built-in: missing value는 알아서 처리함)

2. Feature Selection
Feature 2300개에서 feature importance / target 과의 correlation으로 1000개 정도로 줄임.

5. Training Strategy
- 여러 모델들 Ensemble
- 각 모델들을 피쳐로 해서 다시 학습

6. 다른 참가자와 합치기 (stacking)

그 이후 성능을 더 올리고 싶다면?
- feature generation
- parameter tuning
- more stacking

7. Hyper parameter tuning
모델 파라미터 최적화

Lessions learned:

- Lession1 - Feature generation 과 cross-validation은 함께 해야한다.
(leader board와 로컬 cv가 다를 수 있음)

Featue generation -> cv -> 성능향상 되었는지? -> feature set update

- Lession2 - 모든 결과를 기록해야한다.
날짜 / feature / 설명 / 성능 / parameter

중요한 팁:

- 가장 중요: stable trustworthy validation set 을 준비하는 것이 필수 **
- 잘하는 사람 커널 따라해보고 커널 만들어 보는 게 중요!

이후:

Google Competition: Gstore 의 유저 revenue 예측 참가중..
- 2%의 매출이 나오는 주요 고객들을 분류하는 것이 중요.

## 머신러닝을 위한 수학 - 최적화: 이규영님

최적화
> 어떤 제약 조건하에서 목적 함수 f(x)에 대해 함수를 최소/최대화 하는 x값을 찾는 문제

최적화의 분류)
1. deterministic vs stochastic
- deterministic optimization: 확정적 최적화

각 파라미터들은 고정된 값

머신러닝에서 사용되는 대부분의 최적화 방법들

- stochastic: 확률적 최적화

각 파라미터들은 고정된 값이 아닌 확률분포를 갖는다고 가정

대표문제: 강화학습, 마르코프모델

2. 변수의 형태: Continuous VS Discrete VS Mixed

3. 함수, 제약조건의 형태: Linear Vs Non-linear
- 선형(linear 1차함수)
- one or more nonlinear 2차 이상 함수

변수, 함수의 형태에 따라)
- Linear Programming: 목적함수와 제약식 모두가 선형인 최적화

- Non-linear Programming: 목적함수와 제약식 중 단 하나라도 선형이 아님
(두번 미분이 가능해야함)

** Convex: 증가함수 인가
- 유일한 global minima가 있음. 
- local minima = global minma
- ex) SVM (Quadratic programming으로 최적화 문제를 풀 수 있음)

** Non convex
- gradient descent algorithm으로 풀 수 있음
- neural network / gradient-descent / random serach / model-based search 등

- Integer Programming: 제약조건에 정수 조건이 들어감
물류 최적화 등에 사용

- Integer Non-linear Programming
- Mixed Integer Programming
- Mixed Non-linear Programming

Stochastic optimization
- 목적함수 또는 제약식에 확률분포가 들어감
- ex) 강화학습

[Stochastic optimization 문제를 푸는 방법들]

Stochastic gradient descent

휴리스틱 최적화: 한정된 시간에서 최적의 답을 찾는 것이 아니라 만족할 만한 수준의 해법을 찾는것
(deterministic, stochastic / discrete or continous 모두 적용가능)

- Genetic algorithm: 적자 생존의 아이디어
- 시뮬레이티드 어닐링: 물리적인 담금질 기법
- 안티콜로니시스템: 개미생태계

## 캐글을 위한 캐글: 정권우님
(live 캐글 대회에서 메달을 따기 위한 과거 캐글 경진대회 공부법)

[지금 무엇을 해야할까?]

입문강의 (모두를 위한 머신러닝 / fast.ai 등)를 들었는가

코딩을 할 줄 아는가

=> 그럼 캐글!

[bottom up(이론부터 차근차근) VS top down(일단 그냥 먼저 해보는거)]
- 경진대회 시작 / keras / VGG16 / adam optimization 사용 -> leader board
- 이론들을 문제를 풀기 위해 필요한 수준까지만 이해하고 바로 적용

Q. 무슨 경진대회부터 시작할까?
- 타이타닉 해본 후 Live 경진대회 => 과거 경진대회 중 관심있는 데이터를 다루는 경진대회를 공부!

과거 경진대회 중 어떤 것?
- 1년 내외 최근
- 참여자가 1000명 이상
- 상위 입상자 코드가 내가 사용하는 언어로 되어있는지

처음 도전했던 경진대회
1. 산탄데르 - Top 19%
2. state farm - Top 14% 

좌절 후 액션플랜)
- 캐글 블로그에서 과거 경진대회의 승자 인터뷰 정독 및 번역하기
- 과거 경진대회 상위코드 재현하기
- 혼자서 과거 경진대회 참여하기
(6개월간 2개 정도 공부)

과거 경진대회의 장점)
- 시간 제약이 없음
- Submission 제약이 없음
- 경쟁이 없음

과거 경진대회 공부 방법)
1) EDA
2) Baseline Code (기초 파이프라인 개발) - 시작점
3) Experiments
4) 상위 입상자 코드 재현

그리고)
3번째 산탄데르 제품 추천 문제 - Top 10%, 동메달

Q. 언제부터 팀 빌딩을 하고 문제를 같이 풀어보는게 좋을지?
- 10% 정도는 스스로 할 수 있을 단계까지 먼저 도달하고, 팀 구성해서 협업해보는 것이 좋음.

