---
layout: post
title:  "2019 if kakao 컨퍼런스 후기"
date:   2019-08-30 15:45:00
tags: [ifkakao, 문서분류, 컨퍼런스, 세션]
comments: true
---

# 세션: 밑바닥부터 시작하는 쇼핑 데이터 엔지니어링 고군 분투기

레거시 시스템 개선 과정
카카오 커머스 - 선물하기, 쇼핑하기, 다음 쇼핑 등

## 레거시 시스템의 스케일업 이슈
- 초장기 서비스 형태: 단일 DB구조 -> 애플리케이션 -> 서비스
- 서비스 개발 후 여러가지 운영 이슈 중 누적되는 데이터로 인해 확장의 이슈가 있었음

## 현실적인 해결방안
- DB의 Join 쿼리 제거 > 검색 기능은 elstic search 사용 / DB는 DB로만
- 새로운 데이터에 대해 색인을 만드는 작업이 필요함

## 데이터 파이프라인 구조
DB ~~> Elastic search
- 배치처리
- 실시간 처리
- 전체 복구

### ES 색인을 어떻게 만들까?
- 검색 대상이 되는 필드와 id만 색인함
- **검색에 최적화된 DB와 데이터 저장용 DB의 역할을 분리함!**

### 데이터 변경 감지 솔루션
- CDC 기술 -> 기술스택과 운영노하우가 필요함
- DB의 증분 필드를 pull하는 방식 > 선택

### Pull 방식 데이터 변경 감지 > DB에 의해 자동 갱신됨.
- modified_at, update_ts 을 사용하여 자동 갱신
 
## 실시간 색인

### 실시간 데이터 변경 처리
- 변경된 데이터 -> Kafka -> ETL -> ES

#### 문제점
- 데이터의 순서 보장 필요
- 순서가 보장되더라도 적재된 이벤트를 replay하면서 순간적으로 과거 상태로 회귀하는 이슈 발생 -> 해결 불가능
- 색인에 필요한 모든 데이터를 채워야 하는 부담 발생

(Eventual Consistency 문제)

#### 해결
- 변경된 데이터를 id만 kafka에서 받고, id로 DB의 데이터를 조회해서 색인 데이터를 가져옴

## 실시간, 배치, 데이터 복구 파이프라인
- 실시간: spark streaming
- 배치: spark batch (hopping 방식으로 안정적으로 처리)
- 전체 색인 복구: 
  - spark recovery (예전데이터보다 최신 데이터부터 복구함)
  - data skew문제로 id 단위로 복구함

## 데이터 품질을 유지하기 위한 노력
### 로직 검증을 위한 테스트 환경 구조
- DB fixture 데이터 생성
- Join service 호출
- ES join 쿼리 생성
- 쿼리 결과 검증

### 검색 요구사항 별 테스트 케이스를 모두 만듦

### 운영환경의 복구
- zookeeper로 모니터링 및 자동 복구

# 세션: 카카오와 다음의 컨텐츠들은 어떻게 분류되고 있을까?

## 포털에서 콘텐츠 분류를 왜 하는가?
- 대/소 분류체계로 콘텐츠가 분류되고 있음
- 이전엔 콘텐츠를 찾기위해 많은 단계를 거쳐야했음 -> 찾는데에 많은 힘을 써야했음
- 콘텐츠 찾는 시간을 줄이기 위해 다 리스트업 했더니 너무 많고 복잡해짐
- 자동 분류가 필요해짐

### 자동 분류 후
- 분류된 후 대량의 콘텐츠를 파악하기 좋아짐
- 기간 별 콘텐츠의 경향도 쉽게 파악할 수 있음
- 유저의 취향에 맞는 콘텐츠를 제공해주기 쉬워짐

## 학습 셋 구축 과정
### 사례참고
- 카카오 내/외부 여러 서비스들에서 분류 체계를 참고함
- 카테고리 정보를 수집함

### 현황 파악 뼈대 만들기
- 분류할 카테고리 체계를 구축함
- **분류 가능할만큼 데이터가 있는지 판단**
- **너무 유사한 카테고리가 있지 않은지, 세부 카테고리가 존대하는게 나을지**
- 감정형 카테고리를 넣을 것인지 판단 (다른 카테고리들과 잘 섞임)

### 카테고리 구체화
- 카테고리간 경계 명확화

### 학습 셋 구축
- 카테고리별 학습셋 수백개 이상
- 제목, 본문을 발췌하여 카테고리 페이지별로 올림
- csv형태로 다운로드
- 하나의 학습셋으로 만듦

### ML Model 타당성 검증
- confusion matrix로 검증

### 카테고리 통합, 제외
- 정확도가 낮거나 효용성이 떨어지는 카테고리는 통합, 제외함

현황 ->> 통합/제외 * n회 반복

### 인사이트
- 카테고리의 개수가 적절할 떼 학습 성능이 좋았음 (개수 자체보다 도메인에 맞는 개수가 중요!)
- 학습 셋의 숫자는 중요하다 (테스트 셋의 개수가 많은 편이 실 예측의 성능이 더 잘 나옴)
- 학습셋 구축은 고품질 노동 집약적 분야임
  - 한두 개가 아닌 최소 몇 만개
  - 도메인 전문가가 필요 (겹치는 성격의 카테고리, 모호한 카테고리가 많음)
- 학습 셋 구축 과정 효율화, 자동화 필요성 (데이터 양, 버전 관리, 카테고리 별 콘텐츠 수량 파악)

## 똑똑하게 학습 셋 관리하는 법

두가지 메인 포인트: 수정 (잘못 매핑된 데이터), 추가 (신규 데이터)

### 학습 셋 어드민
- 카테고리 리스팅, 수량, 콘텐츠 추가/수정/삭제

### 히스토리 관리
- 롤백 지원
- 더티체크

### 색, 시각화를 통해 라벨링 검증 효율화
- 부정확한 데이터에 대해 시각화 -> 가장 성능이 좋았던 챔피언 모델로 검증
- **카테고리 별 학습셋에 대해 오분류 개수, 정확도, 실 예측 정확도, 오분류 개수를 표시함**

### 얻게된 것
- 학습셋을 구성하는 운영 인력 감소 (7명 -> 1~2명)
- 지속적인 실제 예측 성능 향상

## 기본모델, fastText알고리즘
- 좋은 모델의 요소: 정확성, 중요한 카테고리 잘 잡아줄 것, 학습 비용 저렴, 빠른 학습 시간, ..등
- **모델에 대한 요구사항을 세세하게 정의하고, 선정된 기준으로 여러가지 모델을 비교함**

### fastText 모델
#### 특성
- 기본 성능이 높음
- 학습 시간이 빠름 (가성비 좋음)
- API 응답 시간이 빠름
- GPU가 필수가 아님

카카오에서 콘텐츠 분류(대/소카테고리)하는 세션 듣고 있는데 여기도 fastText가 프로덕션에서 쓸 때 다른 알고리즘들과 비교해서 기본 성능이 좋고, 학습 시간, API 응답 시간 등 여러 기준에서 퍼포먼스가 좋아서 잘 쓰고 있다고 하네용 ㅎㅎ

#### 학습
- 정답과 오답(정답을 제외한 나머지)을 함께 판별

## 실제 분류가 이루어지는 단계
- **여러개의 모델과 룰 매핑 사용**
- **룰매핑에 가중치를 두지만, 여러개의 모델의 만장일치면 룰 매핑을 이기도록 설정**

# 세션: 상품 카탈로그 자동 생성 ML 모델 소개

## 검색과 상품 카탈로그
### 검색 유입을 통한 유저는 60%가 추가 탐색을 하는 목적성 유저
- 검색결과 <-> 상품상세 (반복) -> 최종 구매
- 탐색이 용이할 수록 구매전환율이 높아짐

### 검색 품질에 있어 카탈로그 수와 매핑된 상품의 coverage는 매우 중요한 요소
- 정제된 상품명으로 검색 반응성이 높여줌
- 최저가 정보와 밀접. 상품 매핑수가 많아질수록 가격경쟁력이 올라감

## 카탈로그 자동 생성?
### 왜 머신러닝 모델로 만들었나? 유연성 필요
- 시즌, 트렌드에 민감 -> 수명이 매우 짧음
- 특정 상품의 상품 수가 매우 적어질 수 있음
- 매일 신규 등록되는 상품

## 각 쇼핑몰의 카탈로그 정보가 상이하고 부족한 정보가 많음 - 정제 x
- 매핑 정확도가 낮아짐
- 상품 옵션 표기도 달라짐 (e.g. 18입, 12개 등)

## 자동화 적용 그리고 효과
- 자동화: 동일 상품 묶기, 타이틀 추출
- 품질: edge proportion(동일 상품일 가능성), 비지니스 로직 (서비스 담당자가 컨트롤 가능하도록)
- 적용 범위: 옵션/스펙 유무, 카테고리 난이도 선정

### 자동 카탈로그 (95% 정확도 / 수동: 92% 정확도)
- 패션/뷰티위주 먼저 적용
- 수동vs자동 > (2달치 생산량 - 1년치의 3배)
- 기존 수동 카탈로그에서 누락했던 매핑도 추가됨

## 상품 카탈로그 자동 생성 ML 모델 소개

### 어떤 데이터를 사용했는지?
#### 무엇을 보고 같은 상품이라고 생각할까요?
- 상품 이미지
- 유사한 상품 이름
- 동일한 카테고리

### 전체 과정
#### 카테고리 별 상품 분류 (카카오 아레나에 있음)
#### Vector Model (상품 이미지, 상품 이름) - 고정된 크기의 벡터모델로 변환
- 상품 이미지: VGG19 모델 사용
- 상품 이름: 단어의 순서들이 다름, 명사가 적은 경우, 띄어쓰기가 없는 경우
- 자연어처리: 띄어쓰기, 불용어, 명사위주의 단어구성, 순서바뀌는 상품명, 비교 가능한 임베딩 벡터

#### 상품이름 벡터화
- 키워드 추출 (사내 라이브러리)
- TF-IDF score 적용 (중요한 키워드에 가중치를 높게 줌)
- 임베딩: word2vec (쇼핑상품명 만으로 따로 학습함)
- TF-IDF * word2vec 사용

왜 CNN, RNN을 안쓰는지? - 대화체등과 달리 순서가 중요하지 않음

#### 유사상품 그래프: 서로 비슷한 상품을 연결지어 그래프로 표현
- 이미지 벡터가 유사한 (코사인 유사도 0.9 이상) 상위 100개의 상품을 뽑음 (approximate knn 사용)
- 비슷하게 이름 벡터가 유사한 상품 추출

##### 엣지 케이스
- 실제로 서로 다른 상품인데 임베딩이 비슷함 (구글 홈 미니, 카카오 홈 미니)
- 서로 같은 상품인데 임베딩이 많이 다름 (이미지가 많이 다른 경우)
- approximate knn 으로 부정확한 경우

#### Community detection
- Label Propagation (빠르게 수행하는 그래프 마이닝 알고리즘 사용)

### 카탈로그 품질 평가
- 유사상품 그래프의 연결된 정도로 평가점수를 측정함
- 특정 임계값 이상의 카탈로그만 적용함
- 생성시간: 상품 개수에 따라 거의 선형 증가함

## 상품 카탈로그 생성 더 빠르게 하기
- 그래프 요약
- 분산처리
- 휴리스틱 등

-----

## 적용해 볼 것들
- 학습 셋 운영/관리 전략
- 모델의 능력치에 대한 요구사항을 세부적으로 정의 (높은 정확도 만이 아닌)
- 룰 매핑과 ML모델 혼합해서 활용

